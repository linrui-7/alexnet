from keras.models import Sequential  
from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization
from keras.models import Model
from keras.optimizers import SGD
from keras.datasets import mnist
from keras.layers import Conv2D, MaxPooling2D, Flatten
import numpy as np
import matplotlib.pyplot as plt

import seaborn as sns

from sklearn.metrics import confusion_matrix
 

(X_train, y_train), (X_test, y_test) = mnist.load_data() 
 
 
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , X_train.shape[2],1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] , X_test.shape[2],1)
 
 
Y_train = (np.arange(10) == y_train[:, None]).astype(int)  
Y_test = (np.arange(10) == y_test[:, None]).astype(int)    
 
X_train = X_train/255.0
X_test = X_test / 255.0
 
model = Sequential() # 采用贯序模型

model.add(Conv2D(32,(3,3), input_shape=(28,28,1)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2),strides=1))
 
model.add(Conv2D(64,(3,3)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Conv2D(128,(3,3)))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Conv2D(256,(3,3)))
model.add(BatchNormalization())
model.add(Activation('relu'))
 
 
model.add(MaxPooling2D(pool_size=(2, 2)))
 
model.add(Flatten())
 
model.add(Dense(500)) 
model.add(BatchNormalization())
model.add(Activation('relu')) 
model.add(Dropout(0.5)) 
 
 
model.add(Dense(500))
model.add(BatchNormalization()) 
model.add(Activation('relu'))
model.add(Dropout(0.5))
 
model.add(Dense(500)) 
model.add(Activation('relu'))
 
model.add(Dense(10))
model.add(BatchNormalization())
model.add(Activation('softmax'))
 
 
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])     
 

 
model.fit(X_train, Y_train, batch_size=100, epochs=1, 
              shuffle=True, verbose=2, validation_split=0.3)
train = model.evaluate(X_train, Y_train, verbose=0)
print('Train loss:', train[0])
print('Train accuracy:', train[1])
score = model.evaluate(X_test, Y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])


y_pred = model.predict(X_test)


con_mat = confusion_matrix(y_test, np.argmax(y_pred,axis=1))

con_mat_norm = con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis]     # 归一化
con_mat_norm = np.around(con_mat_norm, decimals=2)

figure = plt.figure(figsize=(8, 8))
sns.heatmap(con_mat, annot=True, cmap='Blues')

plt.ylim(0, 10)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.show()


